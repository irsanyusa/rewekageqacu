<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Unreal Engine 5 Could Change Games, Movies and the Metaverse | ZBlogY</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="A version of this article was published in TIME’s newsletter Into the Metaverse. Subscribe for a weekly guide to the future of the Internet. You can find past issues of the newsletter here.
For years, the 3D software development tool Unreal Engine has powered some of the biggest video games on the market—from Fortnite to Valorant—as well as television shows like The Mandalorian and even Porsche engineering. On Tuesday, Epic Games showed off the public release of Unreal Engine 5, the engine’s first major update in 8 years."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>ZBlogY</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Unreal Engine 5 Could Change Games, Movies and the Metaverse</h1><div><strong>Publish date: </strong>2024-08-09</div><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><i>A version of this article was published in TIME’s newsletter Into the Metaverse. </i><a href=#><i>Subscribe for a weekly guide to the future of the Internet.</i></a> You can find <a href=#>past issues of the newsletter here</a>.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">For years, the 3D software development tool <a href=#>Unreal Engine</a> has powered some of the biggest video games on the market—<a href=#>from </a><a href=#><i>Fortnite </i></a>to <i>Valorant</i>—as well as television shows like <i>The Mandalorian </i>and even <a href=# rel=noopener>Porsche engineering</a>. On Tuesday, Epic Games showed off the public release of Unreal Engine 5, the engine’s first major update in 8 years.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">The company promises that the new updates to Unreal Engine 5 will make it the bedrock for the next generation of Web 3 developments—from metaverse experiences to movies, and of course, video games.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Unreal Engine is the second-most widely used video game engine, trailing only Unity, and is known for its depth of features and visual quality. Unreal Engine 5 augments those strengths, giving its users hyper-intricate 3D detail, facial realism, and large-scale world building. Its release opens the door for Disney to create a live <i>Mandalorian </i>video game that looks nearly as real as the show does, for example, says Kim Libreri, the CTO at Epic Games.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">But top developers at Epic Games and outside of the organization argue that UE5’s biggest impact is not on the biggest studios, but rather smaller, independent developers who can now make high-quality games for much lower costs. Starting today, UE5 is free to download and use, with Epic taking a 5% cut on products created with it only after they earn over $1 million in gross revenue.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><i></i>“We want to allow anyone to make great-looking stuff and take the drudgery out,” Libreri tells TIME. “Nobody should have to make a chair or a rock at this point: we want people to focus on what is truly important, like great gameplay and great artistry.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Leading up to its release, TIME got exclusive access to several developers and artists who have already started using a preview version of Unreal Engine 5. They praised the system and discussed its potential in ushering an array of advancements across industries, including the metaverse. Here’s what’s under the hood.</p><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>Hi-definition 3D imagery</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">In December, Epic teased the release of UE5 with a <a href=# rel=noopener>demo featuring Keanu Reeves and Carrie-Anne Moss</a> of the <i>Matrix</i> franchise. The video showed Reeves and Moss transforming back into their bodies from 23 years ago—when the original <i>Matrix</i> came out—and then being transported into a virtual city to fight off a slew of bad guys. The graphics of the city are startlingly lifelike: the way the sun glints off the top of a car or a wet highway, for instance, or the depth and texture of intricately carved Art Deco reliefs and rusty chain link fences.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">These visual details are boosted by two new technologies in UE5: Lumen, which emulates natural light, and Nanite, which allows for incredibly precise 3D detail. “In the past, as you got closer to surfaces, the realism would break down: you could see that it’s a flat surface with a lot of texture detail as opposed to 3D geometry,” says Nick Penwarden, vice president of engineering at Epic. “Now, the artist can keep chiseling down and put in as much detail as they possibly can.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">There’s a real-world link between <i>The Matrix </i>and UE5: Libreri, now Epic’s CTO, served as a visual effects supervisor of the <i>Matrix </i>franchise, presiding over the <a href=# rel=noopener>“bullet time” technology</a> in the original film. “A lot of us at Epic share the philosophy that the real world and the virtual world can look the same,” he says. “Our whole tagline was: ‘What is real? What is a movie, and what is a game?’”</p><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>Crossing the uncanny valley</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">To create the <i>Matrix Awakens </i>demo, Reeves and Moss flew to a digital scanning specialist studio in Serbia, where they had 3D scans taken of their faces and bodies. These scans were then incorporated into another one of Epic’s new technologies: Metahuman, which creates lifelike avatars. Up to this point, the creation of digital humans has been expensive and complex for developers and filmmakers. Epic’s Metahuman app gives you templates and tools to create characters in minutes, letting you customize the crinkles around their eyes, add freckle patterns, even change the shape of their irises. (Some people are concerned that Metahuman will <a href=# rel=noopener>ease the creation</a> of <a href=#>deepfakes</a>, however.)</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">This technology is especially exciting for filmmakers like Aaron Sims, an artist who used to work with physical prosthetics and makeup for Hollywood movies like <i>Gremlins 2 </i>and Men in Black, and <a href=# rel=noopener>now builds characters and beasts</a> for video games and his own films. “We can take the realism all the way down to the pore,” says Sims. “As someone who used to make puppets and prosthetics, now I can do anything I want—and the foam isn’t going to rip.”</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/api.time.com/wp-content/uploads/2022/04/metahuman_AS.png><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>What’s next for the metaverse</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">To show off the the depth of the new UE5, Epic is releasing the entire city from the<i> Matrix</i> demo, so that developers can build games and experiences on top of it. The world will be populated by 20,000 metahumans driving cars and walking around the city streets, with each block rendered in vivid detail, down to each leaf and brick.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Epic hopes this release shows the possibility of Unreal Engine’s metaverse capabilities, in which high definition, large-scale worlds can be built easily. Another new update, World Partition, breaks down enormous maps into parcels that are manageable for a regular gamer to play without an expensive rig. “We’re also releasing tutorials to show developers that if you’re starting from scratch and want to make your own fantasy city, this is how we did it,” Libreri says.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">With the templates for virtual worlds ready to go, it’s up to companies and developers to fill them with things and events. Libreri anticipates that UE5 will also enable a robust environment of <a href=#>digital twins</a>, in which real life physical objects and environments are replicated in the virtual world. Many industries have begun using UE5 to create prototypes, from car companies like Porsche to architecture firms to manufacturing plants. The fact that these designs are already in UE5 makes it nearly seamless for Porsche to make a virtual 911 that drives inside the Matrix city, for example.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Hybrid live-virtual events are also on the way. Libreri is excited, for instance, about the possibility of concerts that take place in real life, with the performer wearing a motion capture suit, that are then streamed to viewers at home in real time. He also mentions live-virtual game shows and “gamified musical concerts.” “I think that the next evolution of social connectivity is going to happen through these live events,” he says.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">But just because incredibly life-like worlds events can be built in UE5 doesn’t mean every game or metaverse environment will suddenly be intricately lifelike. Developers still need to account for the fact that many devices—including many smart phones—don’t have the capacity to run highly sophisticated graphics. “The more you push fidelity, the fewer devices you can support,” says Jacob Navok, the CEO of Genvid Technologies, which develops tech tools for streaming. (Navok is also a co-writer of <a href=# rel=noopener>Matthew Ball’s influential essays </a>on the metaverse.) “Fortnite and Minecraft have proven that visual fidelity is not necessarily the thing that gets people excited to spend billions of hours inside of virtual worlds.”</p><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>The impact on Fortnite is TBD</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Epic’s flagship game is Fortnite, which has 350 million registered users worldwide. In December, Epic switched Fortnite over to UE5, but <a href=# rel=noopener>very few discernible changes were detected</a> by gamers. Libreri says this was by design: Epic wanted to show how seamless the transition between engines could be. While he is cagey about future changes to Fortnite, he says that the implementation of UE5 could allow Battle Royale Island to grow in size and contestant capacity, as well as open up the game to an array of visual possibilities. “I’d love to see more industrial crossovers. I’d love to experiment with what photorealism can mean in a stylized world,” he says.</p><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>Empowering smaller artists</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Whether or not Fortnite is impacted in the next year, UE5 has already shifted the artistic process of many smaller artists. One of those artists is Daniel Martinger, a 29-year-old Swede who began using a preview version of the engine in December. Martinger had previously used Unity to create 3D environments and surfaces—but using it required some coding, which took him away from the visual aspects of creation.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">For Martinger’s first UE5 project, he decided to create a carpenter’s cellar, complete with shopworn tools and rough surfaces. Working alone several days a week for three months, he created each tool hanging on the shelves individually, dulling ax blades and making slight dents in wooden tables. The resulting video was widely shared around the internet and hailed for its realism.</p><p></p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">“You can play around a lot: using painting tools, blending textures. It’s easier with lighting,” Martinger says. “It feels like Unreal opens up so many doors for me.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Navok says that Epic’s counterintuitive business strategy, of giving their product away for free to low-level developers, relies on the belief that the time and resources spent on virtual worlds will continue to dramatically rise. “If we were in a ‘fixed pie’ world, I would say they’re building tools that allow them to maintain their status quo as the number two engine in the world,” he says. “But Tim [Sweeney, the CEO of Epic Games] is betting that we’re in a ‘growing pie’ world: that the number of developers will multiply next year and the year after, who will need to decide between building on Unity, Unreal, or somewhere else. And that is why they’re focused on cost savings.”</p><h2 class="text-2xl font-bold tracking-0.5px font-zilla-slab self-baseline"><b>Impact on the film industry</b></h2><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Meanwhile, the impact of UE5 on the film industry is likely to expand once filmmakers realize its capabilities for rendering digital objects and scenes quickly and relatively cheaply. Over the past few years, Unreal Engine has been used by big budget shows including <i>Westworld </i>and <i>The Mandalorian</i>, whose showrunners commissioned Epic to erect stages surrounded by massive LED walls. Those hi-definition walls served as a replacement for creating complex sci-fi sets, appearing in the camera as fully three-dimensional. <i>Westworld</i>, for example, was able to shoot a helicopter flying over a city despite everyone being planted firmly on the ground. This technique is likely to become more and more common: Epic says that there are now <a href=# rel=noopener>more than 250 in-camera visual effects stages</a> across the world, up from less than a dozen just two years ago.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Sims, the filmmaker, is using UE5 in a different way: to create entire projects in his home studio. Sims can ask a friend to put on a motion capture suit, watch the corresponding monster inside UE5 in real time, and then adjust his visuals and storytelling accordingly. Last year, he created an entire short film in UE5, <i><a href=# rel=noopener>The Eye: Calenthek</a>.</i> While Sims had originally budgeted three to four months to create the film traditionally, the process inside UE5 took six weeks.<i> </i>“In traditional digital effects, you built something and then it went through a whole process before you knew what it really looked like,” he says. “Now, you don’t need an army of thousands of people to create things anymore, and you get instant gratification.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Sims calls using UE5 a “slight addiction.” “On movie sets, it’s often the case that everything that could go wrong, goes wrong,” he says. “There’s a lot of stress involved, and so much pressure having everyone on set. I feel like these virtual sets we’re creating are a way to be more creative, not have the same stress, and have no limitations.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><a href=#><i>Subscribe to Into the Metaverse for a weekly guide to the future of the Internet.</i></a></p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Join TIMEPieces on <a href=# rel=noopener>Twitter</a> and <a href=# rel=noopener>Discord</a></p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmismaKyb6%2FOpmZvaWZpgHR%2Bjp6noptdqruzscClZJ6ml567pnmUZqOarZ6YtXA%3D</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>